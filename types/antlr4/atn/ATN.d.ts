import LexerAction from "../action/LexerAction";
import RuleContext from "../context/RuleContext";
import IntervalSet from "../misc/IntervalSet";
import ATNState from "../state/ATNState";
import DecisionState from "../state/DecisionState";
import RuleStartState from "../state/RuleStartState";
import RuleStopState from "../state/RuleStopState";
import TokensStartState from "../state/TokensStartState";
import Token from "../Token";

export default class ATN {
    static readonly INVALID_ALT_NUMBER: 0;

    /**
     * Used for runtime deserialization of ATNs from strings
     * The type of the ATN.
     */
    grammarType: number;

    maxTokenType: number;
    states: number[];

    /**
     * Each subrule/rule is a decision point and we must track them so we
     * can go back later and build DFA predictors for them.  This includes
     * all the rules, subrules, optional blocks, ()+, ()* etc...
     */
    decisionToState: DecisionState[];

    ruleToStartState: RuleStartState[];
    ruleToStopState: RuleStopState[];
    modeNameToStartState: Record<string, TokensStartState>;

    /**
     * For lexer ATNs, this maps the rule index to the resulting token type.
     * For parser ATNs, this maps the rule index to the generated bypass token
     * type if the {@link ATNDeserializationOptions.isGenerateRuleBypassTransitions}
     * deserialization option was specified; otherwise, this is `null`
     */
    ruleToTokenType: number[];

    /**
     * For lexer ATNs, this is an array of {@link LexerAction} objects which may
     * be referenced by action transitions in the ATN
     */
    lexerActions: LexerAction[];

    modeToStartState: TokensStartState[];

    constructor(grammarType: number, maxTokenType: number);

    /**
     * Compute the set of valid tokens that can occur starting in state `s`.
     * If `ctx` is null, the set of tokens will not include what can follow
     * the rule surrounding `s`. In other words, the set will be
     * restricted to tokens reachable staying within `s`'s rule
     */
    nextTokensInContext(s: ATNState, ctx?: RuleContext): IntervalSet;

    /**
     * Compute the set of valid tokens that can occur starting in `s` and
     * staying in same rule. {@link Token.EPSILON} is in set if we reach end of
     * rule
     */
    nextTokensNoContext(s: ATNState): IntervalSet;

    nextTokens(s: ATNState, ctx?: RuleContext): IntervalSet;

    addState(state: ATNState): void;

    removeState(state: ATNState): void;

    defineDecisionState(s: DecisionState): number;

    getDecisionState(decision: number): DecisionState;

    /**
     * Computes the set of input symbols which could follow ATN state number
     * `stateNumber` in the specified full `context`. This method
     * considers the complete parser context, but does not evaluate semantic
     * predicates (i.e. all predicates encountered during the calculation are
     * assumed true). If a path in the ATN exists from the starting state to the
     * {@link RuleStopState} of the outermost context without matching any
     * symbols, {@link Token.EOF} is added to the returned set.
     *
     * If `context` is `null`, it is treated as {@link ParserRuleContext.EMPTY}.
     *
     * @param stateNumber the ATN state number
     * @param ctx the full parse context
     *
     * @return The set of potentially valid input symbols which could follow the
     * specified state in the specified context.
     */
    getExpectedTokens(stateNumber: number, ctx: RuleContext): IntervalSet;
}
